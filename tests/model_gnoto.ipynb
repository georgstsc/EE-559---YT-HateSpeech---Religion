{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Model Training: Religious Hate Speech Classifier\n",
    "\n",
    "This notebook fine-tunes a transformer-based model to detect **religious hate speech** in user comments.\n",
    "\n",
    "The training data comes from our `data.ipynb` preprocessing pipeline, which extracted and weakly labeled comments based on:\n",
    "- Keyword-based religious mention detection\n",
    "- Toxicity thresholds\n",
    "\n",
    "We train on a **balanced dataset** to improve detection of minority class (`hate = 1`) and evaluate model performance on both validation and test splits.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Notebook Overview\n",
    "\n",
    "1. 📥 Load balanced train/val/test splits\n",
    "2. 🔤 Tokenize using Hugging Face tokenizer\n",
    "3. 🏗️ Fine-tune transformer (starting with a small model for fast experimentation)\n",
    "4. 📈 Evaluate metrics: accuracy, precision, recall, F1, confusion matrix\n",
    "5. 💾 Save trained model for use on Gnoto or downstream inference\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not use pip without activating a virtual environment first!\n",
      "Otherwise, you might break your default Python environment and not be able to start Jupyter again.\n",
      "Check the Documentation on how to deal with virtual environments:\n",
      "🗀 / Documentation / 10_Envs_and_kernels.ipynb\n",
      "✅ Dataset loaded\n",
      "Train: 143708 | Val: 17964 | Test: 17964\n",
      "                                                    text  label\n",
      "62942  It's like saying \"I don't hate Jews, I hate Ju...      1\n",
      "96104  Another Islamic terror attack in Europe.  Sure...      1\n",
      "97559  The problem is Islam, it has always been Islam...      1\n"
     ]
    }
   ],
   "source": [
    "# ✅ Install if missing\n",
    "!pip install transformers scikit-learn --quiet\n",
    "\n",
    "# 📚 Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ✅ Load balanced dataset\n",
    "train_df = pd.read_csv(\"../data/train_balanced.csv\")\n",
    "val_df = pd.read_csv(\"../data/val_balanced.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_balanced.csv\")\n",
    "\n",
    "print(\"✅ Dataset loaded\")\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(train_df.sample(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔤 Tokenization with Hugging Face Tokenizer\n",
    "\n",
    "We tokenize the text using a pretrained tokenizer compatible with our selected model.  \n",
    "We'll use [`prajjwal1/bert-tiny`](https://huggingface.co/prajjwal1/bert-tiny) — a lightweight BERT variant for fast testing and prototyping.\n",
    "\n",
    "Later on Gnoto, we can easily switch to a more powerful model like `microsoft/deberta-v3-small` without changing the code logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0aa22092ba74bd6900fc98e422bbe65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4493082875c4937a29ce0db4419a7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d120839c126e4381bff863b2f780a5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47daa98bb8a4260957f7a6cd4e73dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenization complete\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Required for DeBERTa tokenizer\n",
    "\n",
    "# ✅ Choose model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ✅ Dataset wrapper for PyTorch\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=256)\n",
    "        self.labels = labels.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# ✅ Prepare datasets\n",
    "train_data = CommentDataset(train_df['text'], train_df['label'])\n",
    "val_data = CommentDataset(val_df['text'], val_df['label'])\n",
    "test_data = CommentDataset(test_df['text'], test_df['label'])\n",
    "\n",
    "# ✅ Loaders\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "print(\"✅ Tokenization complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Model Setup and Optimizer\n",
    "\n",
    "We load a lightweight transformer model (`prajjwal1/bert-tiny`) for fast experimentation.  \n",
    "This model will be fine-tuned on our balanced religious hate speech dataset using a binary classification head.\n",
    "\n",
    "We use the `AdamW` optimizer, commonly used for transformer-based models, and push the model to GPU if available (CPU otherwise).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608ed27e8054cd0b7ed83e44b0a2716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "# ✅ Load model with classification head (binary)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# ✅ Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"🖥️ Running on:\", device)\n",
    "\n",
    "# ✅ Set up optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏋️ Training Loop (1 Epoch)\n",
    "\n",
    "We'll train the model using standard PyTorch for 1 quick epoch.  \n",
    "This is just to verify that everything works before scaling it up on GPU (e.g., on Gnoto).\n",
    "\n",
    "During each batch:\n",
    "- We move inputs to the selected device\n",
    "- Compute loss\n",
    "- Backpropagate\n",
    "- Step optimizer\n",
    "\n",
    "We also evaluate the model on the validation set at the end of the epoch using accuracy and F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 981/4491 [16:44<59:53,  1.02s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🚀 Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Move to device\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ One quick epoch\n",
    "EPOCHS = 3\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    print(f\"\\n🚀 Epoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        # Move to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"📉 Avg Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ✅ Evaluation on validation set\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "    print(f\"✅ Val Accuracy: {val_acc:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Final Evaluation on Test Set\n",
    "\n",
    "After training and validation, we now evaluate the model's performance on the test set.  \n",
    "We’ll compute:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- Confusion Matrix\n",
    "\n",
    "This helps us understand how well the model generalizes to unseen religious hate speech examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ Inference\n",
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# ✅ Metrics\n",
    "print(\"📊 Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=[\"Non-Hate\", \"Hate\"]))\n",
    "\n",
    "# ✅ Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Non-Hate\", \"Hate\"], yticklabels=[\"Non-Hate\", \"Hate\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"🧩 Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Save Trained Model and Tokenizer\n",
    "\n",
    "We now save the fine-tuned model and tokenizer locally so that it can be:\n",
    "- Reloaded for inference\n",
    "- Uploaded to Gnoto for full-scale training\n",
    "- Shared with teammates or deployed later\n",
    "\n",
    "This will create a folder containing:\n",
    "- Model weights (`pytorch_model.bin`)\n",
    "- Config and tokenizer files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 📁 Save folder path\n",
    "save_path = \"../models/distilBERT\"\n",
    "\n",
    "# 💾 Save model + tokenizer\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"✅ Model and tokenizer saved to: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
