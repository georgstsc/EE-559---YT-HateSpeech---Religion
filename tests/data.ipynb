{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Dataset Preparation: Religious Hate Speech Classification\n",
    "\n",
    "This notebook prepares the dataset used for training a deep learning model to detect **religious hate speech** in online comments.\n",
    "\n",
    "We use the [`civil_comments`](https://huggingface.co/datasets/civil_comments) dataset from Hugging Face, originally released as part of the [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification) challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Steps in this notebook:\n",
    "\n",
    "1. **Load dataset** from Hugging Face\n",
    "2. **Detect religion-related comments** using keyword-based filtering\n",
    "3. **Apply weak labeling** to define hate speech: `mentions_religion AND toxicity > 0.5`\n",
    "4. **Handle class imbalance** by upsampling hate comments\n",
    "5. **Split dataset** into train / validation / test sets (stratified)\n",
    "6. **Save final datasets** to CSV files for downstream training\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 Output files:\n",
    "\n",
    "All data is saved in the `data/` folder:\n",
    "- `train.csv`, `val.csv`, `test.csv` → original distribution (imbalanced)\n",
    "- `train_balanced.csv`, `val_balanced.csv`, `test_balanced.csv` → 50/50 balanced split for model training\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading 'civil_comments' dataset...\n",
      "🔢 Label distribution:\n",
      "label\n",
      "0    89818\n",
      "1     6818\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Train: 77308 | Val: 9664 | Test: 9664\n",
      "✅ Saved CSVs in ../data/\n"
     ]
    }
   ],
   "source": [
    "# 🧠 Dataset prep for Religious Hate Detection (data.ipynb)\n",
    "\n",
    "# ✅ 1. Install datasets package if needed\n",
    "!pip install datasets --quiet\n",
    "\n",
    "# ✅ 2. Load dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "print(\"🔄 Loading 'civil_comments' dataset...\")\n",
    "dataset = load_dataset(\"civil_comments\")\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# ✅ 3. Clean & drop nulls\n",
    "df = df[df['text'].notna()]\n",
    "\n",
    "# ✅ 4. Define religion-related keywords\n",
    "religion_keywords = [\n",
    "    \"muslim\", \"islam\", \"islamic\", \"jew\", \"jewish\", \"judaism\",\n",
    "    \"christian\", \"christianity\", \"bible\", \"jesus\", \"god\", \"catholic\", \"pope\",\n",
    "    \"hindu\", \"hinduism\", \"buddha\", \"buddhist\", \"atheist\", \"religion\", \"religious\"\n",
    "]\n",
    "\n",
    "def mentions_religion(text):\n",
    "    text = str(text).lower()\n",
    "    return any(re.search(rf\"\\b{kw}\\b\", text) for kw in religion_keywords)\n",
    "\n",
    "# ✅ 5. Apply religion detection + weak labeling\n",
    "df['mentions_religion'] = df['text'].apply(mentions_religion)\n",
    "df['religious_hate'] = (df['mentions_religion']) & (df['toxicity'] > 0.5)\n",
    "df_filtered = df[df['mentions_religion']].copy()\n",
    "df_filtered['label'] = df_filtered['religious_hate'].astype(int)\n",
    "\n",
    "# ✅ 6. Show basic stats\n",
    "print(\"🔢 Label distribution:\")\n",
    "print(df_filtered['label'].value_counts())\n",
    "\n",
    "# ✅ 7. Train / Val / Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df_filtered['text'], df_filtered['label'], test_size=0.2, stratify=df_filtered['label'], random_state=42\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ✅ 8. Save to CSV in data/ folder\n",
    "train_df = pd.DataFrame({'text': train_texts, 'label': train_labels})\n",
    "val_df = pd.DataFrame({'text': val_texts, 'label': val_labels})\n",
    "test_df = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
    "\n",
    "train_df.to_csv(\"../data/train.csv\", index=False)\n",
    "val_df.to_csv(\"../data/val.csv\", index=False)\n",
    "test_df.to_csv(\"../data/test.csv\", index=False)\n",
    "\n",
    "# ✅ 9. Confirm sizes\n",
    "print(f\"\\n📊 Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(\"✅ Saved CSVs in ../data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Labeling and Class Imbalance\n",
    "\n",
    "After loading the `civil_comments` dataset and labeling comments that:\n",
    "- (1) Mention religion (using keyword matching), and\n",
    "- (2) Have high toxicity scores (`toxicity > 0.5`),\n",
    "\n",
    "we found that only a small fraction of comments were labeled as **religious hate speech**.\n",
    "\n",
    "| Label        | Count   | Percent |\n",
    "|--------------|---------|---------|\n",
    "| Non-Hate     | ~93%    | 89,818  |\n",
    "| Hate         | ~7%     | 6,818   |\n",
    "\n",
    "This class imbalance is a problem for training deep learning models, especially since they tend to learn the majority class by default, ignoring the minority. Our earlier model achieved high accuracy, but very low recall and F1-score on the hate class.\n",
    "\n",
    "To address this:\n",
    "- We **upsample** the hate class (duplicate those examples)\n",
    "- We build a **balanced dataset** for training and evaluation\n",
    "- We also retain the original dataset for later comparison\n",
    "\n",
    "This approach will allow the model to learn more meaningful patterns related to religious hate speech in a balanced setting, and then later be tested on imbalanced, real-world data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original counts → Hate: 6818, Non-hate: 89818\n",
      "Balanced counts → Hate: 89818, Non-hate: 89818\n",
      "✅ Saved balanced dataset to ../data/\n"
     ]
    }
   ],
   "source": [
    "# ✅ Create balanced dataset with equal hate and non-hate\n",
    "\n",
    "# 🧪 Separate classes\n",
    "df_hate = df_filtered[df_filtered[\"label\"] == 1]\n",
    "df_non_hate = df_filtered[df_filtered[\"label\"] == 0]\n",
    "\n",
    "print(f\"Original counts → Hate: {len(df_hate)}, Non-hate: {len(df_non_hate)}\")\n",
    "\n",
    "# ✅ Upsample the hate class to match non-hate count\n",
    "df_hate_upsampled = df_hate.sample(n=len(df_non_hate), replace=True, random_state=42)\n",
    "\n",
    "# ✅ Combine to create a balanced dataset\n",
    "df_balanced = pd.concat([df_non_hate, df_hate_upsampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(f\"Balanced counts → Hate: {df_balanced['label'].sum()}, Non-hate: {(df_balanced['label']==0).sum()}\")\n",
    "\n",
    "# ✅ Train/val/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df_balanced['text'], df_balanced['label'], test_size=0.2, stratify=df_balanced['label'], random_state=42\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ✅ Save to CSV\n",
    "pd.DataFrame({'text': train_texts, 'label': train_labels}).to_csv(\"../data/train_balanced.csv\", index=False)\n",
    "pd.DataFrame({'text': val_texts, 'label': val_labels}).to_csv(\"../data/val_balanced.csv\", index=False)\n",
    "pd.DataFrame({'text': test_texts, 'label': test_labels}).to_csv(\"../data/test_balanced.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved balanced dataset to ../data/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
