{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Dataset Preparation: Religious Hate Speech Classification\n",
    "\n",
    "This notebook prepares the dataset used for training a deep learning model to detect **religious hate speech** in online comments.\n",
    "\n",
    "We use the [`civil_comments`](https://huggingface.co/datasets/civil_comments) dataset from Hugging Face, originally released as part of the [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification) challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Steps in this notebook:\n",
    "\n",
    "1. **Load dataset** from Hugging Face\n",
    "2. **Detect religion-related comments** using keyword-based filtering\n",
    "3. **Apply weak labeling** to define hate speech: `mentions_religion AND toxicity > 0.5`\n",
    "4. **Handle class imbalance** by upsampling hate comments\n",
    "5. **Split dataset** into train / validation / test sets (stratified)\n",
    "6. **Save final datasets** to CSV files for downstream training\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Output files:\n",
    "\n",
    "All data is saved in the `data/` folder:\n",
    "- `train.csv`, `val.csv`, `test.csv` ‚Üí original distribution (imbalanced)\n",
    "- `train_balanced.csv`, `val_balanced.csv`, `test_balanced.csv` ‚Üí 50/50 balanced split for model training\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading 'civil_comments' dataset...\n",
      "üî¢ Label distribution:\n",
      "label\n",
      "0    89372\n",
      "1     6762\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# üß† Dataset prep for Religious Hate Detection (data.ipynb)\n",
    "\n",
    "# ‚úÖ 1. Install datasets package if needed\n",
    "!pip install datasets --quiet\n",
    "\n",
    "# ‚úÖ 2. Load dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "print(\"üîÑ Loading 'civil_comments' dataset...\")\n",
    "dataset = load_dataset(\"civil_comments\")\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# ‚úÖ 3. Clean & drop nulls\n",
    "df = df[df['text'].notna()]\n",
    "\n",
    "# ‚úÖ 4. Define religion-related keywords\n",
    "religion_keywords = [\n",
    "    \"muslim\", \"islam\", \"islamic\", \"jew\", \"jewish\", \"judaism\",\n",
    "    \"christian\", \"christianity\", \"bible\", \"jesus\", \"god\", \"catholic\", \"pope\",\n",
    "    \"hindu\", \"hinduism\", \"buddha\", \"buddhist\", \"atheist\", \"religion\", \"religious\"\n",
    "]\n",
    "\n",
    "def mentions_religion(text):\n",
    "    text = str(text).lower()\n",
    "    return any(re.search(rf\"\\b{kw}\\b\", text) for kw in religion_keywords)\n",
    "\n",
    "# ‚úÖ 5. Apply religion detection + weak labeling\n",
    "df['mentions_religion'] = df['text'].apply(mentions_religion)\n",
    "df['religious_hate'] = (df['mentions_religion']) & (df['toxicity'] > 0.5)\n",
    "df_filtered = df[df['mentions_religion']].copy()\n",
    "# üßπ Drop duplicates to prevent data leakage\n",
    "df_filtered = df_filtered.drop_duplicates(subset=\"text\").reset_index(drop=True)\n",
    "df_filtered['label'] = df_filtered['religious_hate'].astype(int)\n",
    "\n",
    "# ‚úÖ 6. Show basic stats\n",
    "print(\"üî¢ Label distribution:\")\n",
    "print(df_filtered['label'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Labeling and Class Imbalance\n",
    "\n",
    "After loading the `civil_comments` dataset and labeling comments that:\n",
    "- (1) Mention religion (using keyword matching), and\n",
    "- (2) Have high toxicity scores (`toxicity > 0.5`),\n",
    "\n",
    "we found that only a small fraction of comments were labeled as **religious hate speech**.\n",
    "\n",
    "| Label        | Count   | Percent |\n",
    "|--------------|---------|---------|\n",
    "| Non-Hate     | ~93%    | 89,818  |\n",
    "| Hate         | ~7%     | 6,818   |\n",
    "\n",
    "This class imbalance is a problem for training deep learning models, especially since they tend to learn the majority class by default, ignoring the minority. Our earlier model achieved high accuracy, but very low recall and F1-score on the hate class.\n",
    "\n",
    "To address this:\n",
    "- We **upsample** the hate class (duplicate those examples)\n",
    "- We build a **balanced dataset** for training and evaluation\n",
    "- We also retain the original dataset for later comparison\n",
    "\n",
    "This approach will allow the model to learn more meaningful patterns related to religious hate speech in a balanced setting, and then later be tested on imbalanced, real-world data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Duplicate comments (same text): 0\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ 7. Train / Val / Test Split\n",
    "duplicate_count = df_filtered.duplicated(subset=\"text\").sum()\n",
    "print(f\"üß† Duplicate comments (same text): {duplicate_count}\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ Split before upsampling\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_filtered, test_size=0.2, stratify=df_filtered[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# ‚úÖ Upsample hate in the training set only\n",
    "df_hate = train_df[train_df[\"label\"] == 1]\n",
    "df_non_hate = train_df[train_df[\"label\"] == 0]\n",
    "\n",
    "df_hate_upsampled = df_hate.sample(n=len(df_non_hate), replace=True, random_state=42)\n",
    "train_balanced_df = pd.concat([df_non_hate, df_hate_upsampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "# ‚úÖ Save\n",
    "train_balanced_df.to_csv(\"../data/train_balanced.csv\", index=False)\n",
    "val_df.to_csv(\"../data/val_balanced.csv\", index=False)\n",
    "test_df.to_csv(\"../data/test_balanced.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Overlapping comments: 0\n"
     ]
    }
   ],
   "source": [
    "overlap = set(train_df['text']) & set(test_df['text'])\n",
    "print(f\"‚ö†Ô∏è Overlapping comments: {len(overlap)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
